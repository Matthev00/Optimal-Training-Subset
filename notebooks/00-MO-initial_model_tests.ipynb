{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Modele"
      ],
      "metadata": {
        "id": "VbrKuMioe48S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "def get_fashion_mnist_dataloaders(\n",
        "    train_batch_size: int = 64,\n",
        "    val_batch_size: int = 64,\n",
        "    val_split: float = 0.2,\n",
        "    seed: int = 42\n",
        "):\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    train_dataset = datasets.FashionMNIST(\n",
        "        root=\"./data\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    val_size = int(len(train_dataset) * val_split)\n",
        "    train_size = len(train_dataset) - val_size\n",
        "\n",
        "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=train_batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=val_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "dMI2Y9KTrMOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Axbklcu6qpkm"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleFCN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleFCN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-nsIuABov92j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mobilenet(num_classes: int = 100, in_chanels = 3) -> nn.Module:\n",
        "\n",
        "    model_weights = torchvision.models.MobileNet_V3_Small_Weights.DEFAULT\n",
        "    transforms = model_weights.transforms()\n",
        "    model = torchvision.models.mobilenet_v3_small(weights=model_weights)\n",
        "\n",
        "    if in_chanels != 3:\n",
        "      model.features[0][0] = nn.Conv2d(\n",
        "          in_channels=in_chanels,\n",
        "          out_channels=model.features[0][0].out_channels,\n",
        "          kernel_size=model.features[0][0].kernel_size,\n",
        "          stride=model.features[0][0].stride,\n",
        "          padding=model.features[0][0].padding,\n",
        "          bias=False\n",
        "      )\n",
        "\n",
        "\n",
        "    for param in model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "    model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
        "\n",
        "    return model, transforms"
      ],
      "metadata": {
        "id": "RhCF7qCS1OS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_effnetb0(out_features):\n",
        "    effnetb0_weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "    transforms = effnetb0_weights.transforms()\n",
        "    model = torchvision.models.efficientnet_b0(weights=effnetb0_weights) # noqa 5501\n",
        "\n",
        "    for param in model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.2, inplace=True),\n",
        "        nn.Linear(in_features=1280,\n",
        "                  out_features=out_features,\n",
        "                  bias=True))\n",
        "\n",
        "    model.name = \"effnetb0\"\n",
        "    return model, transforms"
      ],
      "metadata": {
        "id": "AkDdaGgw3uJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_effnetb7(out_features):\n",
        "    effnetb7_weights = torchvision.models.EfficientNet_B7_Weights.DEFAULT\n",
        "    transforms = effnetb7_weights.transforms()\n",
        "    model = torchvision.models.efficientnet_b7(weights=effnetb7_weights) # noqa 5501\n",
        "\n",
        "    for param in model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.2, inplace=True),\n",
        "        nn.Linear(in_features=2560,\n",
        "                  out_features=out_features,\n",
        "                  bias=True))\n",
        "\n",
        "    model.name = \"effnetb7\"\n",
        "    return model, transforms"
      ],
      "metadata": {
        "id": "AcqpsJlo5qtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(\n",
        "    model: nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    num_epochs: int = 5,\n",
        "    learning_rate: float = 1e-3,\n",
        "):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "        print(f\"Train Loss: {train_loss / len(train_loader):.4f}\")\n",
        "        print(f\"Val Loss: {val_loss / len(val_loader):.4f}\")\n",
        "        print(f\"Val Accuracy: {100. * correct / total:.2f}%\")\n",
        "        print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "tRNeav5RxaYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms, models\n",
        "import torchvision\n",
        "\n",
        "\n",
        "def get_cifar100_dataloaders(\n",
        "    train_batch_size: int = 64,\n",
        "    val_batch_size: int = 64,\n",
        "    val_split: float = 0.2,\n",
        "    seed: int = 42,\n",
        "    transform=None\n",
        ") -> tuple[DataLoader, DataLoader]:\n",
        "\n",
        "    train_dataset = datasets.CIFAR100(\n",
        "        root=\"./data\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    val_size = int(len(train_dataset) * val_split)\n",
        "    train_size = len(train_dataset) - val_size\n",
        "\n",
        "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=train_batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=val_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "ljgwV5tWt8HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FashionMNIST"
      ],
      "metadata": {
        "id": "XzjNOzyr2nwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "train_dataloader, test_dataloader = get_fashion_mnist_dataloaders()\n",
        "train_model(model, train_dataloader, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpjxPzfA11iG",
        "outputId": "94b9f545-6a4e-4af7-8303-f85e40fa7011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [00:14<00:56, 14.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]\n",
            "Train Loss: 0.5103\n",
            "Val Loss: 0.3645\n",
            "Val Accuracy: 87.05%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:28<00:43, 14.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5]\n",
            "Train Loss: 0.3290\n",
            "Val Loss: 0.3253\n",
            "Val Accuracy: 88.16%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:42<00:28, 14.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5]\n",
            "Train Loss: 0.2800\n",
            "Val Loss: 0.2845\n",
            "Val Accuracy: 89.63%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:57<00:14, 14.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5]\n",
            "Train Loss: 0.2464\n",
            "Val Loss: 0.2689\n",
            "Val Accuracy: 90.31%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [01:12<00:00, 14.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5]\n",
            "Train Loss: 0.2240\n",
            "Val Loss: 0.2456\n",
            "Val Accuracy: 90.67%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_mobilenet(num_classes=10, in_chanels=1)[0]\n",
        "train_dataloader, test_dataloader = get_fashion_mnist_dataloaders()\n",
        "train_model(model, train_dataloader, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K43_Ch1cAacT",
        "outputId": "21c38e4a-244e-4898-93af-8e05831bd903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [00:20<01:21, 20.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]\n",
            "Train Loss: 1.3990\n",
            "Val Loss: 1.1597\n",
            "Val Accuracy: 57.77%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:41<01:02, 20.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5]\n",
            "Train Loss: 1.2035\n",
            "Val Loss: 1.1105\n",
            "Val Accuracy: 59.48%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [01:02<00:41, 20.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5]\n",
            "Train Loss: 1.1531\n",
            "Val Loss: 1.0819\n",
            "Val Accuracy: 60.17%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [01:23<00:20, 20.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5]\n",
            "Train Loss: 1.1208\n",
            "Val Loss: 1.0580\n",
            "Val Accuracy: 61.49%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [01:44<00:00, 20.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5]\n",
            "Train Loss: 1.1081\n",
            "Val Loss: 1.0603\n",
            "Val Accuracy: 61.59%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR-100"
      ],
      "metadata": {
        "id": "mU9P6eDQ2qa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, transform = get_effnetb0(out_features=100)\n",
        "train_dataloader, test_dataloader = get_cifar100_dataloaders(transform=transform)\n",
        "train_model(model, train_dataloader, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gTJ9zeHzeWs",
        "outputId": "b9dab48e-7af8-4310-a12a-15142f3d46bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [02:30<10:02, 150.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]\n",
            "Train Loss: 2.5018\n",
            "Val Loss: 1.7005\n",
            "Val Accuracy: 56.99%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [04:59<07:28, 149.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5]\n",
            "Train Loss: 1.6876\n",
            "Val Loss: 1.5221\n",
            "Val Accuracy: 59.64%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [07:28<04:58, 149.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5]\n",
            "Train Loss: 1.5186\n",
            "Val Loss: 1.4709\n",
            "Val Accuracy: 60.59%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [09:59<02:30, 150.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5]\n",
            "Train Loss: 1.4165\n",
            "Val Loss: 1.4164\n",
            "Val Accuracy: 61.65%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [12:29<00:00, 149.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5]\n",
            "Train Loss: 1.3563\n",
            "Val Loss: 1.4225\n",
            "Val Accuracy: 61.39%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, transform = get_mobilenet()\n",
        "train_dataloader, test_dataloader = get_cifar100_dataloaders(transform=transform)\n",
        "train_model(model, train_dataloader, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTlJN7YE5G3q",
        "outputId": "bb6120c7-bbbc-4430-f52c-069484bf0418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [02:07<08:28, 127.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]\n",
            "Train Loss: 1.9814\n",
            "Val Loss: 1.7155\n",
            "Val Accuracy: 53.50%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [04:14<06:21, 127.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5]\n",
            "Train Loss: 1.4239\n",
            "Val Loss: 1.4226\n",
            "Val Accuracy: 59.85%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [06:21<04:14, 127.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5]\n",
            "Train Loss: 1.2488\n",
            "Val Loss: 1.3940\n",
            "Val Accuracy: 61.01%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [08:29<02:07, 127.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5]\n",
            "Train Loss: 1.1174\n",
            "Val Loss: 1.3886\n",
            "Val Accuracy: 61.15%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [10:35<00:00, 127.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5]\n",
            "Train Loss: 1.0071\n",
            "Val Loss: 1.3802\n",
            "Val Accuracy: 62.25%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, transform = get_effnetb7(out_features=100)\n",
        "train_dataloader, test_dataloader = get_cifar100_dataloaders(transform=transform)\n",
        "train_model(model, train_dataloader, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4BTKMiz6NW9",
        "outputId": "c4bf63e4-189d-41f0-b125-ccd33766896b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        }
      ]
    }
  ]
}